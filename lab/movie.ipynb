{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>총알파티총알파티총알파티</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>뭐라고 딱히 할말이 없습니다.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>무슨 좀비영화 보는줄....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스토리는 괜찮은데..   중간 중간 긴장감이 좀 떨어짐 그런데로 볼만함</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이야기 전개는 스피디하지만 뻔한 결말이어서 그럭저럭 킬링타임용에 그치는군</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review  rating\n",
       "0                              총알파티총알파티총알파티      10\n",
       "1                          뭐라고 딱히 할말이 없습니다.       5\n",
       "2                           무슨 좀비영화 보는줄....       6\n",
       "3   스토리는 괜찮은데..   중간 중간 긴장감이 좀 떨어짐 그런데로 볼만함       6\n",
       "4  이야기 전개는 스피디하지만 뻔한 결말이어서 그럭저럭 킬링타임용에 그치는군       6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class CNNReg(nn.Module):\n",
    "    def __init__(self, vocaNum, embedding_dim):\n",
    "        super(CNNReg, self).__init__()\n",
    "        self.kernel_size = [2, 3, 4, 5]\n",
    "        self.channel_out = 10\n",
    "        self.embedding = nn.Embedding(vocaNum, embedding_dim)\n",
    "        self.conv1 = nn.ModuleList([nn.Conv2d(1, self.channel_out, (k, embedding_dim)) for k in self.kernel_size])\n",
    "        self.linear1 = nn.Linear(self.channel_out*len(self.kernel_size), 10)\n",
    "        self.linear2 = nn.Linear(10, 1)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)   # (N, W, D)\n",
    "        embed = embed.unsqueeze(1)  # (N,1,W,D), 1: channel_in\n",
    "\n",
    "        # [(N,Channel_out,W,1), ...] * len(Kernel_size)\n",
    "        feature_maps = [F.relu(conv(embed)) for conv in self.conv1]\n",
    "        \n",
    "        # [(N,Channel_out,W), ...] * len(Kernel_size)\n",
    "        feature_maps = [feature_map.squeeze(3) for feature_map in feature_maps]\n",
    "\n",
    "        # [(N, Channel_out), ...] * len(Kernel_size)\n",
    "        pooled_output = [F.max_pool1d(feature_map, feature_map.size(2)) for feature_map in feature_maps]\n",
    "        output = torch.cat(pooled_output, 1)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.dropout(output)\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear2(output)\n",
    "        return output\n",
    "\n",
    "def makeBatch(batch_sequences, max_len=100):\n",
    "    batch_sequences = [torch.Tensor(sequence) for sequence in batch_sequences]\n",
    "    lengths = [len(sequence) for sequence in batch_sequences]\n",
    "    output = torch.zeros(len(batch_sequences), max_len)\n",
    "    for i, sequence in enumerate(batch_sequences):\n",
    "        length = lengths[i]\n",
    "        output[i, :length] = sequence[:length]\n",
    "    output = output.long()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = defaultdict(list)\n",
    "datas = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len, max_len = 3, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, rate in df.values:\n",
    "    try:\n",
    "        if len(review) > min_len and len(review) < max_len:\n",
    "            morphs = tagger.morphs(review)\n",
    "            words[int(rate)].append(morphs)\n",
    "            datas.append((morphs, rate))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "words = pickle.load(open('words.p', 'rb'))\n",
    "datas = pickle.load(open('datas.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Counter()\n",
    "for score, tags in words.items():\n",
    "    for tag in tags:\n",
    "        voc.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_num = 20000\n",
    "inv = [v[0] for v in voc.most_common(voca_num - 2)]\n",
    "inv.append('<UNK>')\n",
    "inv.insert(0, '<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin = {v: i for i, v in enumerate(inv)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [([(vin[word] if word in vin else vin['<UNK>']) for word in review], rating) for review, rating in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(samples, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = map(list, zip(*train))\n",
    "testX, testY = map(list, zip(*test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "epoch = 10\n",
    "batch_size = 32\n",
    "num_iter = int(len(train) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = CNNReg(len(voc), embedding_dim)\n",
    "reg.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "opt = torch.optim.Adam(reg.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epoch):\n",
    "    for i in range(num_iter):\n",
    "        opt.zero_grad()\n",
    "        batchX = trainX[i*batch_size:(i+1)*batch_size]\n",
    "        batchY = trainY[i*batch_size:(i+1)*batch_size]\n",
    "        batchX = makeBatch(batchX)\n",
    "        batchY = torch.FloatTensor(batchY)\n",
    "\n",
    "        batchX = Variable(batchX).cuda()\n",
    "        batchY = Variable(batchY).cuda()\n",
    "\n",
    "        predict = reg(batchX)\n",
    "        loss = criterion(predict, batchY)\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(reg.state_dict(), 'cnn_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sample_data/movie_review/train/train_data') as f:\n",
    "    test_text = list(map(lambda line: line.strip(), f.readlines()))\n",
    "with open('../sample_data/movie_review/train/train_label') as f:\n",
    "    test_label = list(map(lambda line: int(line.strip()), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    if isinstance(text, str):\n",
    "        text = [[vin[word] if word in vin else vin['<UNK>'] for word in tagger.morphs(text)]]\n",
    "    else:\n",
    "        text = [text]\n",
    "    text = makeBatch(text)\n",
    "    text = Variable(text)\n",
    "    return reg(text).data.tolist()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNReg(\n",
       "  (embedding): Embedding(109035, 200)\n",
       "  (conv1): ModuleList(\n",
       "    (0): Conv2d (1, 10, kernel_size=(2, 200), stride=(1, 1))\n",
       "    (1): Conv2d (1, 10, kernel_size=(3, 200), stride=(1, 1))\n",
       "    (2): Conv2d (1, 10, kernel_size=(4, 200), stride=(1, 1))\n",
       "    (3): Conv2d (1, 10, kernel_size=(5, 200), stride=(1, 1))\n",
       "  )\n",
       "  (linear1): Linear(in_features=40, out_features=10)\n",
       "  (linear2): Linear(in_features=10, out_features=1)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = CNNReg(len(voc), embedding_dim)\n",
    "reg.load_state_dict(torch.load(\"cnn_regression.pkl\"))\n",
    "reg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [predict(text) - label for text, label in zip(test_text, test_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [abs(predict(text) - label) for text, label in zip(testX, testY)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.788670440079557"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.256997108459473"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('초딩 스토리에 발연기들 그리고 갓배운 아마추어 캠코더구준 화면구성과 연출력 이어지는 발편집 ㅋ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.256997108459473"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('<아마추어>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
